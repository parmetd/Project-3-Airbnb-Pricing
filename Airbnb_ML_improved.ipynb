{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\ensemble\\weight_boosting.py:29: DeprecationWarning: numpy.core.umath_tests is an internal NumPy module and should not be imported. It will be removed in a future NumPy release.\n",
      "  from numpy.core.umath_tests import inner1d\n"
     ]
    }
   ],
   "source": [
    "#dependencies\n",
    "\n",
    "#Import linear algebra and data manipulation\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "\n",
    "#Import machine learning\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "import xgboost\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import metrics\n",
    "from sklearn.metrics import mean_squared_error\n",
    "import math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "listings.csv dataset contains information on 3723 listings provided by 2732 hosts.\n"
     ]
    }
   ],
   "source": [
    "#read the dataset\n",
    "listings_df = pd.read_csv('./listings.csv')\n",
    "\n",
    "#find number of listings and number of hosts\n",
    "listings_number = listings_df['id'].count()\n",
    "hosts_number = len(listings_df['host_id'].unique())\n",
    "\n",
    "print('listings.csv dataset contains information on %d listings provided by %d hosts.' % (listings_number, \n",
    "                                                                                          hosts_number))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Helper functions for dataset cleaning\n",
    "def get_host_since_year(row):\n",
    "    ''' Get year from a date represented as a string '''\n",
    "    try:\n",
    "        host_since = int(row['host_since'].split('-')[0])\n",
    "    except:\n",
    "        host_since = np.nan\n",
    "    return host_since\n",
    "\n",
    "def get_val_from_list(row, column_name, value):\n",
    "    ''' Fill in dummy column for values '''\n",
    "    val = 0.0\n",
    "    try:\n",
    "        vals = row[column_name].replace('[', '').replace(\"'\", '').replace(\"]\", '').replace('\"', '').replace('{', '').replace('}', '').split(',')\n",
    "        if value in vals:\n",
    "            val = 1.0\n",
    "    except:\n",
    "        val = 0.0\n",
    "    return val\n",
    "\n",
    "def split_list_into_columns(df, column_name, max_dummies_num = 10):\n",
    "    ''' Split values in columns, which contain lists (for example, amenities) '''\n",
    "    \n",
    "    # get dictionary of unique values in lists across dataset rows\n",
    "    values_dict = {}\n",
    "\n",
    "    for unique_value in df[column_name].unique(): \n",
    "        for value in unique_value.replace('[', '').replace(\"'\", '').replace(\"]\", '').replace('\"', '').replace('{', '').replace('}', '').split(','):\n",
    "            if value in values_dict:\n",
    "                values_dict[value] = values_dict[value] + 1\n",
    "            else:\n",
    "                values_dict[value] = 0\n",
    "                \n",
    "    values_sorted = sorted(values_dict.items(), key=lambda kv: kv[1], reverse = True)\n",
    "      \n",
    "    # split into columns\n",
    "    for value in values_sorted[: max_dummies_num]:\n",
    "        df[column_name + '_' + value[0]] = df.apply(lambda row: get_val_from_list(row, column_name, value[0]),axis=1)\n",
    "        \n",
    "    return\n",
    "\n",
    "def get_extra_people_fee(row):\n",
    "    ''' Return 1 when the is fee for exatra people '''\n",
    "    if row['extra_people'] == '$0.00':\n",
    "        return 0.0\n",
    "    else:\n",
    "        return 1.0\n",
    "\n",
    "#Main dataset cleaning function\n",
    "def clean_dataset(listings_df):\n",
    "    '''\n",
    "    INPUT\n",
    "    listings_df - pandas dataframe containing listings data \n",
    "        \n",
    "    OUTPUT\n",
    "    df - cleaned dataset, which contains merged tables:\n",
    "    1. irrelevant columns are dropped;\n",
    "    2. string containing dates are converted into numbers;\n",
    "    3. columns, containing lists, are split into several columns (for example, amenities)\n",
    "    4. missing values are imputed with mean or mode.\n",
    "    '''\n",
    "   \n",
    "    #drop the irrelevant columns\n",
    "    columns_to_drop = ['host_id','host_location','host_acceptance_rate','host_neighbourhood',\n",
    "                   'host_total_listings_count', 'weekly_price', 'monthly_price',\n",
    "                   'security_deposit', 'cleaning_fee', 'calendar_updated',\n",
    "                   'listing_url','last_scraped' ,'scrape_id', 'name', 'summary', 'space', 'description',\n",
    "                   'experiences_offered', 'street', 'neighbourhood', 'neighbourhood_cleansed', 'zipcode',\n",
    "                   'neighborhood_overview', 'notes', 'transit', 'thumbnail_url', 'medium_url', 'picture_url',\n",
    "                   'xl_picture_url', 'host_url', 'host_name', 'host_about', 'host_thumbnail_url', 'host_picture_url',\n",
    "                   'city', 'state', 'market', 'smart_location', 'country_code', 'country', 'latitude', 'longitude',\n",
    "                   'is_location_exact', 'square_feet', 'has_availability', 'neighbourhood_group_cleansed',\n",
    "                   'availability_60', 'availability_90', 'availability_365', 'calendar_last_scraped',\n",
    "                  'first_review', 'last_review', 'requires_license', 'license', 'jurisdiction_names',\n",
    "                  'reviews_per_month']\n",
    "    df = listings_df.drop(columns = columns_to_drop) \n",
    "     \n",
    "    #convert price to number\n",
    "    df['price'] = df['price'].str.replace(r'\\$','').str.replace(r'\\,','').astype(float)\n",
    "    \n",
    "    #convert host_since date into number and fill in missing values, drop the original column\n",
    "    df['host_since_year'] = df.apply(lambda row: get_host_since_year(row),axis=1)\n",
    "    df['host_since_year'].fillna(df['host_since_year'].mean(), inplace = True)\n",
    "    df = df.drop(columns = ['host_since'])\n",
    "    \n",
    "    #convert host_response_rate into number and fill in missing values, drop the original column\n",
    "    df['host_response_rate_num'] = df['host_response_rate'].astype(str)\n",
    "    df['host_response_rate_num'] = df['host_response_rate_num'].str.replace(\"%\", \"\").astype(\"float\")\n",
    "    df['host_response_rate_num'].fillna(df['host_response_rate_num'].mean(), inplace = True)\n",
    "    \n",
    "    df['host_response_rate_buckets'] = pd.qcut(df['host_response_rate_num'], 5, labels=False, duplicates = 'drop')\n",
    "    \n",
    "    df = df.drop(columns = ['host_response_rate', 'host_response_rate_num'])\n",
    "    \n",
    "    #fill missing values with mean value for host_listings_count\n",
    "    df['host_listings_count'].fillna(df['host_listings_count'].mean(), inplace = True)\n",
    "    \n",
    "    #split host_verifications into dummy columns and drop the original column\n",
    "    split_list_into_columns(df, 'host_verifications')\n",
    "    df = df.drop(columns = ['host_verifications'])\n",
    "    \n",
    "    #fill in missing values for bathrooms, bedrooms and beds with mode\n",
    "    df['bathrooms'] = df['bathrooms'].fillna(df['bathrooms'].mode()[0])\n",
    "    df['bedrooms'] = df['bedrooms'].fillna(df['bedrooms'].mode()[0])\n",
    "    df['beds'] = df['beds'].fillna(df['beds'].mode()[0])\n",
    "    \n",
    "    #split amenities into dummy columns and drop the original column\n",
    "    split_list_into_columns(df, 'amenities')\n",
    "    df = df.drop(columns = ['amenities'])\n",
    "    \n",
    "    #turn extra people fee into binary column (1 - if fee for extra people is charged, 0 - otherwise)\n",
    "    df['extra_people_fee'] = df.apply(lambda row: get_extra_people_fee(row),axis=1)\n",
    "    df = df.drop(columns = ['extra_people'])\n",
    "    \n",
    "    #fill missing values for review scores columns\n",
    "    review_scores_columns = ['review_scores_rating', 'review_scores_accuracy', 'review_scores_cleanliness',\n",
    "                         'review_scores_checkin', 'review_scores_communication', 'review_scores_location',\n",
    "                        'review_scores_value']\n",
    "    for column in review_scores_columns:\n",
    "        df[column].fillna(df[column].mean(), inplace = True)\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# apply functions above to clean dataset\n",
    "df = clean_dataset(listings_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['id',\n",
       " 'host_response_time',\n",
       " 'host_is_superhost',\n",
       " 'host_listings_count',\n",
       " 'host_has_profile_pic',\n",
       " 'host_identity_verified',\n",
       " 'property_type',\n",
       " 'room_type',\n",
       " 'accommodates',\n",
       " 'bathrooms',\n",
       " 'bedrooms',\n",
       " 'beds',\n",
       " 'bed_type',\n",
       " 'price',\n",
       " 'guests_included',\n",
       " 'minimum_nights',\n",
       " 'maximum_nights',\n",
       " 'availability_30',\n",
       " 'number_of_reviews',\n",
       " 'review_scores_rating',\n",
       " 'review_scores_accuracy',\n",
       " 'review_scores_cleanliness',\n",
       " 'review_scores_checkin',\n",
       " 'review_scores_communication',\n",
       " 'review_scores_location',\n",
       " 'review_scores_value',\n",
       " 'instant_bookable',\n",
       " 'cancellation_policy',\n",
       " 'require_guest_profile_picture',\n",
       " 'require_guest_phone_verification',\n",
       " 'calculated_host_listings_count',\n",
       " 'host_since_year',\n",
       " 'host_response_rate_buckets',\n",
       " 'host_verifications_email',\n",
       " 'host_verifications_ phone',\n",
       " 'host_verifications_ reviews',\n",
       " 'host_verifications_ jumio',\n",
       " 'host_verifications_ facebook',\n",
       " 'host_verifications_ kba',\n",
       " 'host_verifications_ linkedin',\n",
       " 'host_verifications_ google',\n",
       " 'host_verifications_phone',\n",
       " 'host_verifications_ manual_offline',\n",
       " 'amenities_Air Conditioning',\n",
       " 'amenities_Heating',\n",
       " 'amenities_Wireless Internet',\n",
       " 'amenities_Kitchen',\n",
       " 'amenities_Smoke Detector',\n",
       " 'amenities_Washer',\n",
       " 'amenities_Dryer',\n",
       " 'amenities_Internet',\n",
       " 'amenities_Essentials',\n",
       " 'amenities_TV',\n",
       " 'extra_people_fee']"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.columns.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def lr_rf(X, y, TEST_SIZE, RAND_STATE):\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=TEST_SIZE, random_state=RAND_STATE)\n",
    "    model = LinearRegression()\n",
    "    model.fit(X_train, y_train)\n",
    "    predictions = model.predict(X_test)\n",
    "    MSE = mean_squared_error(y_test, predictions)\n",
    "    Error_lr = round(math.sqrt(MSE),2)\n",
    "    r2 = model.score(X_test, y_test)\n",
    "    r2a_lr = 1 - (1-model.score(X_test, y_test))*(len(y_test)-1)/(len(y_test)-X_test.shape[1]-1)\n",
    "    print('Linear Regression Results:')\n",
    "    print(f''' MSE: {MSE}, \\n R2: {r2}, \\n Radjusted: {r2a_lr} \\n Error: {Error_lr} \\n \\n''')\n",
    "    print('----------------------------------------')\n",
    "    regressor = RandomForestRegressor(n_estimators=2000, random_state=RAND_STATE)  \n",
    "    regressor.fit(X_train, y_train)  \n",
    "    y_pred = regressor.predict(X_test)  \n",
    "    Error_rf = np.sqrt(metrics.mean_squared_error(y_test, y_pred))\n",
    "    print('Random Forest Results:')\n",
    "    print('Mean Absolute Error:', metrics.mean_absolute_error(y_test, y_pred))  \n",
    "    print('Mean Squared Error:', metrics.mean_squared_error(y_test, y_pred))  \n",
    "    print('Root Mean Squared Error:', np.sqrt(metrics.mean_squared_error(y_test, y_pred))) \n",
    "    print(f'R: {regressor.score(X_test, y_test)}')\n",
    "    r2a_rf = 1 - (1-regressor.score(X_test, y_test))*(len(y_test)-1)/(len(y_test)-X_test.shape[1]-1)\n",
    "    print(f'RAdjusted: {r2a_rf}')\n",
    "    print(f'Error: {Error_rf}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Minimum price per listing is $10.0.\n",
      "Maximum price per listing is $2822.0.\n",
      "Average price per listing is $149.16599516518937.\n"
     ]
    }
   ],
   "source": [
    "#find minimum, maximum and average price for listing\n",
    "min_price = df['price'].min()\n",
    "max_price = df['price'].max()\n",
    "mean_price = df['price'].mean()\n",
    "\n",
    "print(f'Minimum price per listing is ${min_price}.')\n",
    "print(f'Maximum price per listing is ${max_price}.')\n",
    "print(f'Average price per listing is ${mean_price}.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "695.0"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = df[df['price'] <= 699]\n",
    "df['price'].max()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "30"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = df[df['minimum_nights'] <= 31]\n",
    "df['minimum_nights'].max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3274, 54)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "golden_df = df.dropna()\n",
    "golden_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "#creating CSV file of the improved golden version \n",
    "\n",
    "golden_df.to_csv('goldenimproved.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "#turn categorical columns into dummies\n",
    "cat_columns = list(golden_df.select_dtypes(include=['object']).columns)\n",
    "    \n",
    "for col in  cat_columns:\n",
    "    golden_df = pd.concat([golden_df.drop(col, axis=1), pd.get_dummies(golden_df[col], prefix=col, prefix_sep='_',\n",
    "\n",
    "                                                         drop_first=True, dummy_na=True)], axis=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3274, 80) (3274,)\n"
     ]
    }
   ],
   "source": [
    "X = golden_df.drop(columns = ['price', 'id'])\n",
    "y = golden_df[\"price\"]\n",
    "print(X.shape, y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Linear Regression Results:\n",
      " MSE: 2835.1475881994365, \n",
      " R2: 0.6511192328188828, \n",
      " Radjusted: 0.6201763709846374 \n",
      " Error: 53.25 \n",
      " \n",
      "\n",
      "----------------------------------------\n",
      "Random Forest Results:\n",
      "Mean Absolute Error: 32.632378510762685\n",
      "Mean Squared Error: 2634.6259800756975\n",
      "Root Mean Squared Error: 51.32860781353511\n",
      "R: 0.6757945381785699\n",
      "RAdjusted: 0.6470401734937424\n",
      "Error: 51.32860781353511\n"
     ]
    }
   ],
   "source": [
    "lr_rf(X, y, 0.3, 42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
